---
title: "PCA"
output:
  html_document:
    df_print: paged
    highlight: tango
  pdf_document: default
---

Tutorial ini adalah bagian dari kuliah Fundamen Sains Data, Informatika UII. 

#### Contoh 1
Pada contoh ini, kita akan menggunakan data set `USArrest` dari package `datasets`, yang berisi 50 observasi dari negara-negara bagian di Amerika Serikat tentang presentase penangkapan tindak kejahatan per 100.000 orang. Tindak kejahatan tersebut terbagi ke dalam beberapa macam: `Murder`, `Assault`, dan `Rape`. Selain itu, data ini juga mencatat `UrbanPop` presentase populasi yang melakukan urbanisasi. Pertama, mari kita lihat bentuk dan sebaran datanya.

```{r, attr.source = ".numberLines"}
data("USArrests")
head(USArrests)
par(mfrow=c(2,2))
for(i in 1:ncol(USArrests)) {
  hist(USArrests[, i], main = paste(colnames(USArrests[i])), xlab = "")
}
```

Selanjutnya, kita mengaplikasikan PCA pada data tersebut, menggunkaan fungsi `prcomp()` dari package `stats`. Parameter `scale=TRUE, center=TRUE` memastikan nilai setiap variabel distandarisasi, sehingga semua variabel memiliki skala nilai yang sama.


```{r,  attr.source = ".numberLines"}
pcaModel <- prcomp(USArrests, scale. = TRUE, center = TRUE)
pcaModel$rotation
```

Baris 2 mengembalikan `matrix rotation` yang setiap kolomnya madalah eigenvector yang mengindikasikan principal component pertama hingga `p` (dimana `p` adalah jumlah variabel di data set). `pcaModel$x` memberikan proyeksi setiap data point ke semua principal component.

Untuk kemudahan interpretasi, kita dapat memvisualisasikan *biplot* nya.

```{r, message=FALSE, warning=FALSE}
library(factoextra)

fviz_pca_biplot(pcaModel, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969"  # Individuals color
)

```

Dari biplot di atas, sumbu horizontal (Dim1) merepresentasikan principal component yang pertama, yang mengandung 62% variance dari seluruh data set; sumbu vertikal (Dim2) merepresentasikan principal component kedua, yang mengandung 24.7% variance. Dari dua component ini saja, 86.7% variance atau informasi yang dikandung data dapat dijelaskan.  Di sini dapat kita lihat, dari contoh yang relatif kecil dengan empat variabel saja, kita hanya butuh dua "variabel" (principal component) saja untuk merepresentasikan hampir 90% informasi yang ada di data. Ini adalah semangat dimensionality reduction yang menjadi tujuan PCA.

Kemudian pada biplot di atas, juga divisualisasikan setiap variabel sebagai bentuk vektor (panah biru). Dari plot tersebut, dapat kita lihat arah vektor `Murder`, `Assault`, dan `Rape` cenderung horizontal seperti arah principal component yang pertama  (Dim1). Ini mengindikasikan bahwa variable `Murder`, `Assault`, dan `Rape` lebih banyak dijelaskan/diwakili oleh principal komponen yang pertama. Sebaliknya, arah vektor `UrbanPop` lebih mendekati arah principal component yang kedua (dim2). Ini mengindikasikan jika informasi yang dibawa variabel `UrbanPop` lebih banyak diwakili oleh principal component yang kedua.

Dari biplot di atas kita juga dapat menarasikan temuan, sebagai contoh, bahwa angka kriminal (`murder`, `assault`, dan `rape`) lebih banyak terjadi di negara bagian Florida (karena lebih searah dengan vektor `murder`, `assault`, dan `rape`) dibanding dengan Pennsylvania. Kita juga dapat lihat jika angka urbanisasi di New Jersey lebih tinggi (karena lebih searah dengan vektor `UrbanPop`) jika dibandingkan dengan Arkansas.

Selanjutnya kita dapat memvisualisasikan variance yang dibawa setiap component melalui screeplot sebagai berikut. Seperti dijelaskan di atas, dapat kita lihat component 1 dan 2 menjelaskan hampir 90% variance di data.

```{r}
fviz_eig(pcaModel)
```

#### Contoh 2
Pada contoh ini kita akan mengaplikasikan PCA pada data set `mtcars` dari package `datasets` yang berisi 32 observasi (mobil) yang dihitung berdasarkan 11 variabel, lihat `?mtcars` untuk lebih detilnya. Di sini kita akan menggunakan semua variabel kecual variabel 8 dan 9 (tipe mesin dan tipe transmisi yang bersifat diskrit/kategori).

```{r}
dataMPG <- mtcars[, -c(8,9)]
mtcarsPca <- prcomp(dataMPG, scale. = TRUE, center=TRUE)

fviz_pca_biplot(mtcarsPca, repel = TRUE,
                col.var = "#2E9FDF",
                col.ind = "#696969"
)
fviz_eig(mtcarsPca)
```

##### Latihan 1: dari Contoh 2
1. Berapa total variance yang dijelaskan dua principal component pertama?
2. Jelaskan variabel apa saja yang dijelaskan oleh principal component pertama dan kedua?
3. Dalam hal pemakaian bahan bakar (`mpg`), manakah yang lebih hemat antara Datsun 710 dan Merc 450SLC? Jelaskan dalam konteks biplot di atas.
3. Sebutkan mobil-mobil yang daya pacunya (`hp`) lebih besar ketimbang mobil lainnya.

##### Latihan 2
1. Lakukan analisis PCA terhadap `iris dataset`!
2. Berikan penjelasan pada setiap langkah yang anda lakukan dan buat visualisasinya!
3. Berikan kesimpulan anda dari hasil yang diperoleh!